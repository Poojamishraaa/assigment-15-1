{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 : Naukari.com Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium import\n",
    "from selenium  import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#pandas import\n",
    "import pandas as pd\n",
    "\n",
    "#import time\n",
    "import time\n",
    "\n",
    "class NaukariScrapping(object):\n",
    "    \"\"\"\n",
    "    This class will responsible for the scrapping data from the \"naukari.com\"\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        This cunstrocotro will help the cunsumtion\n",
    "        \"\"\"\"\"\n",
    "        #inisilizating the path \n",
    "        self.path = r\"C:\\Users\\ASHISH\\Desktop\\project\\chromedriver.exe\"\n",
    "        \n",
    "        #the driver will be the responsible for the path\n",
    "        self.driver = webdriver.Chrome(self.path)\n",
    "\n",
    "    def scrapping_data(self):\n",
    "        \"\"\"\n",
    "        This function will responsible for the scrapping data and creating dataframe \n",
    "        return : N/A\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        self.driver.get(\"https://www.naukri.com/\")\n",
    "        self.driver.maximize_window()\n",
    "        time.sleep(3)\n",
    "        \n",
    "        self.job_dicrtition = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"root\"]/div[6]/div/div/div[1]/div/div/div/input')))\n",
    "        self.job_dicrtition.send_keys('Data Analyst')\n",
    "        self.job_location = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"root\"]/div[6]/div/div/div[5]/div/div/div/input')))\n",
    "        self.job_location.send_keys('Bangalore')\n",
    "\n",
    "        self.click_button = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"root\"]/div[6]/div/div/div[6]')))\n",
    "        self.click_button.click()\n",
    "\n",
    "        #job cards xpath\n",
    "        first_path_head = '//*[@id=\"root\"]/div[4]/div/div/section[2]/div[2]/article['                  \n",
    "        last_path_tail = ']/div[1]/div[1]/a'\n",
    "        full_path = ''\n",
    "        \n",
    "        # creating empty list for requried data \n",
    "        self.job_heading = list()\n",
    "        self.job_posted_by = list()\n",
    "        self.salary = list()\n",
    "        self.working_exprince = list()\n",
    "        self.job_location = list()\n",
    "        \n",
    "        #scrapping requried data and appending to the list\n",
    "        for i in range(1,11):\n",
    "            full_path = first_path_head+str(i)+last_path_tail\n",
    "            \n",
    "            #scrapping the data from the top 10 result\n",
    "            self.job_title = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, full_path)))\n",
    "            self.job_title_text = self.job_title.text\n",
    "            self.job_heading.append(self.job_title_text)\n",
    "\n",
    "            #job posted by company xpath\n",
    "            company_xpath= first_path_head+str(i)+']/div[1]/div[1]/div/a[1]' \n",
    "            self.company = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, company_xpath)))\n",
    "            self.company_text = self.company.text\n",
    "            self.job_posted_by.append(self.company_text)\n",
    "\n",
    "            #job work exprience\n",
    "            work_exprince_xpath = first_path_head+str(i)+']/div[1]/ul/li[1]/span[1]'\n",
    "            self.working_exprince_path = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, work_exprince_xpath)))\n",
    "            self.working_exprince_text = self.working_exprince_path.text\n",
    "            self.working_exprince.append(self.working_exprince_text)\n",
    "            # print(self.working_exprince)\n",
    "\n",
    "            #job salary\n",
    "            job_salary_xpath = first_path_head+str(i)+']/div[1]/ul/li[2]/span[1]'\n",
    "            self.job_location_path = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, job_salary_xpath)))\n",
    "            self.job_salary_text = self.job_location_path.text\n",
    "            self.salary.append(self.job_salary_text)\n",
    "\n",
    "            #job location\n",
    "            job_location_xpath = first_path_head+str(i)+']/div[1]/ul/li[3]/span'\n",
    "            self.location_path = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, job_location_xpath)))\n",
    "            self.job_location_text = self.location_path.text\n",
    "            self.job_location.append(self.job_location_text)\n",
    "            \n",
    "        #creating dataframe\n",
    "        columns_heading = ['JOB TITLE', 'COMPANY', 'SALARY', 'WORKING EXPRINCE', 'LOCATION']\n",
    "        self.job_dataframe = pd.DataFrame(list(zip(self.job_heading,self.job_posted_by,self.salary,self.working_exprince,self.job_location)),columns=columns_heading)\n",
    "\n",
    "        print(self.job_dataframe)\n",
    "\n",
    "        # closing the browser\n",
    "        self.driver.quit()\n",
    " \n",
    "#creating object for the class\n",
    "NaukariScrapping_obj = NaukariScrapping()\n",
    "\n",
    "#calling the function\n",
    "NaukariScrapping_obj.scrapping_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 : Filpkart assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium import\n",
    "from selenium  import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#pandas import\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#import time\n",
    "import time\n",
    "\n",
    "class FilpkatScrapping(object):\n",
    "    \"\"\"\n",
    "    This class will responsible for the scrapping data from the \"flipkart.com\"\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        This cunstrocotro will help the cunsumtion\n",
    "        \"\"\"\"\"\n",
    "        #inisilizating the path \n",
    "        self.path = r\"C:\\Users\\ASHISH\\Desktop\\project\\chromedriver.exe\"\n",
    "        \n",
    "        #the driver will be the responsible for the path\n",
    "        self.driver = webdriver.Chrome(self.path)\n",
    "\n",
    "        self.brand_name = list()\n",
    "\n",
    "    def scrapping_data(self):\n",
    "        self.driver.get(\"https://www.flipkart.com/\")\n",
    "        self.driver.maximize_window()\n",
    "        time.sleep(3)\n",
    "\n",
    "        search_tag = self.driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "        if self.driver.find_element_by_xpath('/html/body/div[2]/div/div/button'):\n",
    "            login_clear = self.driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "            login_clear.click()\n",
    "        search_tag.send_keys('sunglass')\n",
    "        search_tag.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        first_path_head = '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div['\n",
    "        send_xpath_tail = ']/div/div[1]/div/div/div[1]'    \n",
    "        self.count = 0\n",
    "        self.path_count = 1\n",
    "\n",
    "        brand_list = list()\n",
    "        for i in range(2,103):\n",
    "            self.count += 1\n",
    "            self.path_count += 1\n",
    "            firs_status = None\n",
    "            if self.driver.find_element_by_xpath(first_path_head+str(self.path_count)+send_xpath_tail):\n",
    "                full_path = first_path_head+str(self.path_count)+send_xpath_tail\n",
    "                brand_1 = self.driver.find_element_by_xpath(full_path).text\n",
    "                discription_path = first_path_head+str(self.path_count)+']/div/div['+str(self.path_count)+']/a[1]'\n",
    "                discription = self.driver.find_element_by_xpath\n",
    "                brand_list.append(brand_1)\n",
    "                firs_status = True\n",
    "            if firs_status == True:\n",
    "                for j in range(2,5):\n",
    "                    sub_full_path = first_path_head+str(self.path_count)+']/div/div['+str(j)+']/div/div/div[1]'\n",
    "                    brand = self.driver.find_element_by_xpath(sub_full_path).text\n",
    "                    brand_list.append(brand)\n",
    "            if self.count == 10:\n",
    "                self.count = 0\n",
    "                self.path_count = 1\n",
    "                next = self.driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "                next.click()\n",
    "                time.sleep(4)\n",
    "\n",
    "            # creating dataframe\n",
    "        dataframe = pd.DataFrame(brand_list)\n",
    "        print(dataframe)\n",
    "\n",
    "filpkar_obj = FilpkatScrapping()\n",
    "filpkar_obj.scrapping_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 review filpkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium import\n",
    "from selenium  import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#pandas import\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#import time\n",
    "import time\n",
    "\n",
    "class FilpkatScrapping(object):\n",
    "    \"\"\"\n",
    "    This class will responsible for the scrapping data from the \"flipkart.com\"\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        This cunstrocotro will help the cunsumtion\n",
    "        \"\"\"\"\"\n",
    "        #inisilizating the path \n",
    "        self.path = r\"C:\\Users\\ASHISH\\Desktop\\project\\chromedriver.exe\"\n",
    "        \n",
    "        #the driver will be the responsible for the path\n",
    "        self.driver = webdriver.Chrome(self.path)\n",
    "\n",
    "        self.rating_number = list()\n",
    "        self.rating_infromation_text = list()\n",
    "        self.review_text = list()\n",
    "\n",
    "    def scrapping_data(self):\n",
    "        self.driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")\n",
    "        self.driver.maximize_window()\n",
    "        time.sleep(3)\n",
    "\n",
    "        # rating = self.driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[3]/div/div/div/div[1]/div').text\n",
    "        xpath_rating_head = '//*[@id=\"container\"]/div/div[3]/div/div[1]/div[2]/div['\n",
    "        xpath_rating_tail = ']/div/div/div/div[1]/div'\n",
    "        count = 2\n",
    "        count_range = 0\n",
    "        for i in range(3,104):\n",
    "            count +=1 \n",
    "            count_range +=1\n",
    "            print(count_range)\n",
    "            rating = self.driver.find_element_by_xpath(xpath_rating_head+str(count)+xpath_rating_tail).text\n",
    "            self.rating_number.append(rating)\n",
    "            product_information = self.driver.find_element_by_xpath(xpath_rating_head+str(count)+']/div/div/div/div[1]/p').text\n",
    "            self.rating_infromation_text.append(product_information)\n",
    "            product_review = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, xpath_rating_head+str(count)+']/div/div/div/div[2]/div/div/div')))\n",
    "            product_review_status = product_review.text \n",
    "            self.review_text.append(product_review_status)\n",
    "            print(product_information)\n",
    "            if count_range == 10:\n",
    "                print('am herer')\n",
    "                count_range = 0\n",
    "                count = 2\n",
    "                next_button = self.driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "                next_button.send_keys(Keys.ENTER)\n",
    "                # next.click()\n",
    "                time.sleep(4)\n",
    "        self.driver.quit()\n",
    "\n",
    "        # creating dataframe\n",
    "        columns_heading = ['Product Rating', 'Title', 'Review']\n",
    "        self.job_dataframe = pd.DataFrame(list(zip(self.rating_number,self.rating_infromation_text,self.review_text)),columns=columns_heading)\n",
    "        print(self.job_dataframe)\n",
    "\n",
    "\n",
    "filpkar_obj = FilpkatScrapping()\n",
    "filpkar_obj.scrapping_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Qutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASHISH\\AppData\\Local\\Temp\\ipykernel_9772\\3590984169.py:27: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = webdriver.Chrome(self.path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Author                   Quetos           Type\n",
      "0            Michael Porter           Michael Porter        Essence\n",
      "1                Golda Meir               Golda Meir    Inspiration\n",
      "2        Theodore Roosevelt       Theodore Roosevelt        Country\n",
      "3            Nelson Mandela           Nelson Mandela  Inspirational\n",
      "4              Erma Bombeck             Erma Bombeck    4th Of July\n",
      "5               John Wooden              John Wooden  Inspirational\n",
      "6           Albert Einstein          Albert Einstein         Strong\n",
      "7               Frank Zappa              Frank Zappa  Inspirational\n",
      "8          William Faulkner         William Faulkner          Truth\n",
      "9               Will Rogers              Will Rogers          Funny\n",
      "10             Jimmy Carter             Jimmy Carter         Strong\n",
      "11          Albert Einstein          Albert Einstein           Love\n",
      "12          Abraham Lincoln          Abraham Lincoln        Freedom\n",
      "13          Steven Weinberg          Steven Weinberg            God\n",
      "14    Franklin D. Roosevelt    Franklin D. Roosevelt        Respect\n",
      "15          Albert Einstein          Albert Einstein  Inspirational\n",
      "16             Maya Angelou             Maya Angelou  Inspirational\n",
      "17               Mark Twain               Mark Twain           Love\n",
      "18       Theodore Roosevelt       Theodore Roosevelt      Inspiring\n",
      "19          Michael Jackson          Michael Jackson  Inspirational\n",
      "20  Martin Luther King, Jr.  Martin Luther King, Jr.           Love\n",
      "21              C. S. Lewis              C. S. Lewis    Forgiveness\n",
      "22       Theodore Roosevelt       Theodore Roosevelt        Country\n",
      "23               Mark Twain               Mark Twain  Inspirational\n",
      "24          Abraham Lincoln          Abraham Lincoln  Inspirational\n",
      "25              Ruth Graham              Ruth Graham           Love\n",
      "26              C. S. Lewis              C. S. Lewis          Faith\n",
      "27             Groucho Marx             Groucho Marx            Art\n",
      "28              John Lennon              John Lennon  Inspirational\n",
      "29             Barbara Bush             Barbara Bush  Inspirational\n",
      "30          Albert Einstein          Albert Einstein      Happiness\n",
      "31             Francis Chan             Francis Chan  Inspirational\n"
     ]
    }
   ],
   "source": [
    "#selenium import\n",
    "from selenium  import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#pandas import\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#import time\n",
    "import time\n",
    "\n",
    "class QuotesScrapping(object):\n",
    "    \"\"\"\n",
    "    This class will responsible for the scrapping data from the \"flipkart.com\"\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        This cunstrocotro will help the cunsumtion\n",
    "        \"\"\"\"\"\n",
    "        #inisilizating the path \n",
    "        self.path = r\"C:\\Users\\ASHISH\\Desktop\\project\\chromedriver.exe\"\n",
    "        \n",
    "        #the driver will be the responsible for the path\n",
    "        self.driver = webdriver.Chrome(self.path)\n",
    "\n",
    "        self.rating_number = list()\n",
    "        self.rating_infromation_text = list()\n",
    "        self.review_text = list()\n",
    "\n",
    "    def scrapping_data(self):\n",
    "        self.driver.get(\"https://www.azquotes.com/top_quotes.html\")\n",
    "        self.driver.maximize_window()\n",
    "        time.sleep(3)\n",
    "\n",
    "        top = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"menu\"]/div/div[3]/ul/li[5]/a')))\n",
    "        top.send_keys(Keys.ENTER)\n",
    "\n",
    "        xpath_author_head = '//*[@id=\"content\"]/div/div[1]/div/ul/li['\n",
    "        xpath_author_tail = ']/div/div[1]/a'\n",
    "        self.author_name = list()\n",
    "        self.author_quetos = list()\n",
    "        self.quetos_types = list()\n",
    "\n",
    "        for i in range (1,33):\n",
    "            author = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, xpath_author_head+str(i)+xpath_author_tail)))\n",
    "            text_author = author.text\n",
    "            self.author_name.append(text_author)\n",
    "\n",
    "            author_quetos = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, xpath_author_head+str(i)+']/div/div[1]/a')))\n",
    "            author_quetos_text = author_quetos.text\n",
    "            self.author_quetos.append(author_quetos_text)\n",
    "            quetos_types_elem = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, xpath_author_head+str(i)+']/div/div[2]/div[1]/a[1]')))\n",
    "            text_quetos_type = quetos_types_elem.text\n",
    "            self.quetos_types.append(text_quetos_type)\n",
    "\n",
    "        self.driver.quit()\n",
    "\n",
    "        # creatind dataframe\n",
    "        columns_heading = ['Author', 'Quetos', 'Type']\n",
    "        self.quetos_dataframe = pd.DataFrame(list(zip(self.author_name,self.author_quetos,self.quetos_types)),columns=columns_heading)\n",
    "        print(self.quetos_dataframe)\n",
    "\n",
    "filpkar_obj = QuotesScrapping()\n",
    "filpkar_obj.scrapping_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jagaran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASHISH\\AppData\\Local\\Temp\\ipykernel_9772\\3754977300.py:27: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = webdriver.Chrome(self.path)\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=109.0.5414.75)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x01026643]\n\t(No symbol) [0x00FBBE21]\n\t(No symbol) [0x00EBDA9D]\n\t(No symbol) [0x00E9EF6A]\n\t(No symbol) [0x00F13AAB]\n\t(No symbol) [0x00F261B6]\n\t(No symbol) [0x00F0FB76]\n\t(No symbol) [0x00EE49C1]\n\t(No symbol) [0x00EE5E5D]\n\tGetHandleVerifier [0x0129A142+2497106]\n\tGetHandleVerifier [0x012C85D3+2686691]\n\tGetHandleVerifier [0x012CBB9C+2700460]\n\tGetHandleVerifier [0x010D3B10+635936]\n\t(No symbol) [0x00FC4A1F]\n\t(No symbol) [0x00FCA418]\n\t(No symbol) [0x00FCA505]\n\t(No symbol) [0x00FD508B]\n\tBaseThreadInitThunk [0x764000F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77587BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77587B8E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 49\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[39mprint\u001b[39m(df)\n\u001b[0;32m     48\u001b[0m filpkar_obj \u001b[39m=\u001b[39m JagranScrapping()\n\u001b[1;32m---> 49\u001b[0m filpkar_obj\u001b[39m.\u001b[39;49mscrapping_data()\n",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m, in \u001b[0;36mJagranScrapping.scrapping_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscrapping_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 34\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdriver\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://www.jagranjosh.com/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver\u001b[39m.\u001b[39mmaximize_window()\n\u001b[0;32m     36\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASHISH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:455\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    452\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m: url})\n",
      "File \u001b[1;32mc:\\Users\\ASHISH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    445\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    446\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\ASHISH\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=109.0.5414.75)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x01026643]\n\t(No symbol) [0x00FBBE21]\n\t(No symbol) [0x00EBDA9D]\n\t(No symbol) [0x00E9EF6A]\n\t(No symbol) [0x00F13AAB]\n\t(No symbol) [0x00F261B6]\n\t(No symbol) [0x00F0FB76]\n\t(No symbol) [0x00EE49C1]\n\t(No symbol) [0x00EE5E5D]\n\tGetHandleVerifier [0x0129A142+2497106]\n\tGetHandleVerifier [0x012C85D3+2686691]\n\tGetHandleVerifier [0x012CBB9C+2700460]\n\tGetHandleVerifier [0x010D3B10+635936]\n\t(No symbol) [0x00FC4A1F]\n\t(No symbol) [0x00FCA418]\n\t(No symbol) [0x00FCA505]\n\t(No symbol) [0x00FD508B]\n\tBaseThreadInitThunk [0x764000F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77587BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77587B8E+238]\n"
     ]
    }
   ],
   "source": [
    "#selenium import\n",
    "from selenium  import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#pandas import\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#import time\n",
    "import time\n",
    "\n",
    "class JagranScrapping(object):\n",
    "    \"\"\"\n",
    "    This class will responsible for the scrapping data from the \"jagran.com\"\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        This cunstrocotro will help the cunsumtion\n",
    "        \"\"\"\"\"\n",
    "        #inisilizating the path \n",
    "        self.path = r\"C:\\Users\\ASHISH\\Desktop\\project\\chromedriver.exe\"\n",
    "        \n",
    "        #the driver will be the responsible for the path\n",
    "        self.driver = webdriver.Chrome(self.path)\n",
    "\n",
    "        self.rating_number = list()\n",
    "        self.rating_infromation_text = list()\n",
    "        self.review_text = list()\n",
    "\n",
    "    def scrapping_data(self):\n",
    "        self.driver.get(\"https://www.jagranjosh.com/\")\n",
    "        self.driver.maximize_window()\n",
    "        time.sleep(3)\n",
    "\n",
    "        gk_path = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"1540978020504\"]/div[1]/header/div[3]/ul/li[9]/a')))\n",
    "        gk_path.send_keys(Keys.ENTER)\n",
    "        pm_tag = WebDriverWait(self.driver,30).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"popluarGK\"]/ul/li[2]/a')))\n",
    "        pm_tag.send_keys(Keys.ENTER)\n",
    "        time.sleep(6)\n",
    "        df = pd.read_html('https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1')\n",
    "        print(df)\n",
    "\n",
    "\n",
    "\n",
    "filpkar_obj = JagranScrapping()\n",
    "filpkar_obj.scrapping_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f224f65cb137e4a26817ca77bfe6cc753f10feaf8935c40ce27b23714f15b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
